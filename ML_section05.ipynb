{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMqWXcrf5IW9YXXVrrCN44z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ehekaanldk/ML-study/blob/main/ML_section05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*코드 버전업: v1.0 코드 그대로 사용*"
      ],
      "metadata": {
        "id": "w3JuZHsDKOO6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "\n",
        "tf.disable_v2_behavior()"
      ],
      "metadata": {
        "id": "Kqg8c5SGKCEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression\n",
        "\n",
        "가설의 형태(Hypothesis)\n",
        "$$\n",
        "H(X) = \\frac{1}{(1+e^{-W^TX})}\n",
        "$$\n",
        "손실함수의 형태(Cost)\n",
        "$$\n",
        "cost(W) = -\\frac{1}{m} \\sum ylog(H(x)) +(1-y)log(1-H(x))\n",
        "$$\n",
        "최적화(Gradient descent)\n",
        "$$\n",
        "W := W-\\alpha\\frac{∂}{∂W}cost(W)\n",
        "$$"
      ],
      "metadata": {
        "id": "ka4YXM8FX-uP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# x 데이터는 multi matrix\n",
        "# y 데이터는 binary로 주어진다. 0또는 1의 값을 가진다.\n",
        "x_data = [[1,2],[2,3],[3,1],[4,3],[5,3],[6,2]]\n",
        "y_data = [[0],[0],[0],[1],[1],[1]]\n",
        "\n",
        "# X는 (인스턴스의 개수, x의 variable의 개수)\n",
        "# Y는 (인스턴스의 개수, y의 개수)\n",
        "X = tf.placeholder(tf.float32, shape=[None,2])\n",
        "Y = tf.placeholder(tf.float32, shape=[None,1])\n",
        "\n",
        "# W는 (들어오는 값의 개수, 나가는 값의 개수)로 알 수 있다.\n",
        "# 입력 feature(variable)의 개수, 나가는 값의 개수 = (2, 1)\n",
        "# bias는 (나가는 값의 개수)로 알 수 있다.\n",
        "W = tf.Variable(tf.random_normal([2, 1]), name='weight')\n",
        "b = tf.Variable(tf.random_normal([1]), name='bias')"
      ],
      "metadata": {
        "id": "cS-0LFLAuYw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hypothesis\n",
        "hypothesis = tf.sigmoid(tf.matmul(X, W) + b)"
      ],
      "metadata": {
        "id": "cyf4g_9Rw9dO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cost function\n",
        "cost = -tf.reduce_mean(Y*tf.log(hypothesis) + (1-Y)*tf.log(1-hypothesis))"
      ],
      "metadata": {
        "id": "r_kbHYwIx3Up"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# minimize\n",
        "# 직접 미분하지 않고 GradientDescentOptimiser를 사용하여 구할 수 있다.\n",
        "train = tf.train.GradientDescentOptimizer(learning_rate = 0.01).minimize(cost)"
      ],
      "metadata": {
        "id": "yzYKFo13yHcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# T or F로 정확도를 계산한다.\n",
        "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
        "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))"
      ],
      "metadata": {
        "id": "BHFjZIJ7yYbx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습모델\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "\n",
        "  for step in range(10001):\n",
        "    cost_val, _ = sess.run([cost, train], feed_dict = {X: x_data, Y: y_data})\n",
        "    if step % 200 == 0:\n",
        "      print(step, cost_val)\n",
        "\n",
        "  h, c, a = sess.run([hypothesis, predicted, accuracy],\n",
        "                     feed_dict={X:x_data, Y:y_data})\n",
        "  print(\"\\nHypothesis: \", h, \"\\nCorrect (Y): \", c, \"\\nAccuracy: \", a)"
      ],
      "metadata": {
        "id": "t8-Ms-0sy81-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "실제 데이터에 적용해보도록 한다.\n",
        "당뇨병에 대한 데이터를 사용한다.\n"
      ],
      "metadata": {
        "id": "gX7ipC5N0nEa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "xy = np.loadtxt('data-03-diabetes.csv', delimiter=',', dtype=np.float32)\n",
        "x_data = xy[:, 0:-1]\n",
        "y_data = xy[:, [-1]]"
      ],
      "metadata": {
        "id": "ukSooVEp0tue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 입력 X는 (인스턴스의 개수, variable의 개수) = (nan, 8)\n",
        "# 예측 Y는 (인스턴스의 개수, Y) = (nan, 1)\n",
        "X = tf.placeholder(tf.float32, shape=[None,8])\n",
        "Y = tf.placeholder(tf.float32, shape=[None,1])\n",
        "\n",
        "# 가중치 W는 (variable의 개수, Y) = (8, 1)\n",
        "# 바이어스 b는 (Y) = 출력값으로 1\n",
        "W = tf.Variable(tf.random_normal([8, 1]), name='weight')\n",
        "b = tf.Variable(tf.random_normal([1]), name='bias')"
      ],
      "metadata": {
        "id": "WipSXRWvO2Wy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hypothesis\n",
        "hypothesis = tf.sigmoid(tf.matmul(X, W) + b)"
      ],
      "metadata": {
        "id": "OBztDKAa1T3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cost function\n",
        "cost = -tf.reduce_mean(Y*tf.log(hypothesis) + (1-Y)*tf.log(1-hypothesis))"
      ],
      "metadata": {
        "id": "JAc8g78o1T3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# minimize\n",
        "# 직접 미분하지 않고 GradientDescentOptimiser를 사용하여 구할 수 있다.\n",
        "train = tf.train.GradientDescentOptimizer(learning_rate = 0.01).minimize(cost)"
      ],
      "metadata": {
        "id": "Ba6pl1YS1T3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# T or F로 정확도를 계산한다.\n",
        "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
        "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))"
      ],
      "metadata": {
        "id": "ylFWmbkX1T3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습모델\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "\n",
        "  feed = {X: x_data, Y: y_data}\n",
        "  for step in range(10001):\n",
        "    sess.run(train,feed_dict=feed)\n",
        "    if step % 200 == 0:\n",
        "      print(step, sess.run(cost, feed_dict=feed))\n",
        "\n",
        "  h, c, a = sess.run([hypothesis, predicted, accuracy],\n",
        "                     feed_dict=feed)\n",
        "  print(\"\\nHypothesis: \", h, \"\\nCorrect (Y): \", c, \"\\nAccuracy: \", a)"
      ],
      "metadata": {
        "id": "26kOPcAK1T3h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}