{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyO+Y143d0S/rpbLsc1dXqgw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ehekaanldk/ML-study/blob/main/ML_section03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*코드 버전업: v1.0 코드 그대로 사용*"
      ],
      "metadata": {
        "id": "w3JuZHsDKOO6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "\n",
        "tf.disable_v2_behavior()"
      ],
      "metadata": {
        "id": "Kqg8c5SGKCEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "cost의 형태 확인하기"
      ],
      "metadata": {
        "id": "Ucsba_i1wozT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. 그래프 구현\n",
        "X = [1,2,3]\n",
        "Y = [1,2,3]\n",
        "W = tf.placeholder(tf.float32)\n",
        "\n",
        "  # 가설 설정\n",
        "hypothesis = X * W\n",
        "  # 손실함수 설정\n",
        "cost = tf.reduce_mean(tf.square(hypothesis - Y))"
      ],
      "metadata": {
        "id": "tXW1XeYywe5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. 실행\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "  # 그래프를 그리기 위해 W와 cost의 값을 저장할 리스트를 생성\n",
        "W_val = []\n",
        "cost_val = []"
      ],
      "metadata": {
        "id": "47U-7SrtygOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. update graph 와 get results\n",
        "# -30에서 50의 범위 안에서 움직이도록 한다.\n",
        "# 대략-3 ~ 5에서 0.1간격으로 이동\n",
        "\n",
        "for i in range(-30, 50):\n",
        "  feed_W = i * 0.1\n",
        "  curr_cost, curr_W = sess.run([cost,W], feed_dict={W: feed_W}) # W를 값을 feed_W로 넘기면서\n",
        "  W_val.append(curr_W)\n",
        "  cost_val.append(curr_cost)\n",
        "\n",
        "plt.plot(W_val, cost_val)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7ESYMOlcyiDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gradient descent 적용하기\n",
        "\n",
        "일일히 미분과정 보여준다. cost를 간단하게 해서 일일히 미분과정을 볼 수 있지만, 복잡한 경우 GradientDescentOptimiser() 함수를 사용해서 minimize할 수 있다."
      ],
      "metadata": {
        "id": "XUxQbYmqJyJt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 그래프 구현\n",
        "x_data = [1,2,3]\n",
        "y_data = [1,2,3]\n",
        "\n",
        "W = tf.Variable(tf.random_normal([1]), name = \"weight\")\n",
        "X = tf.placeholder(tf.float32)\n",
        "Y = tf.placeholder(tf.float32)\n",
        "\n",
        "  # 가설 설정\n",
        "hypothesis = X * W\n",
        "## 손실함수 설정\n",
        "cost = tf.reduce_sum(tf.square(hypothesis - Y))"
      ],
      "metadata": {
        "id": "T5TRC1XUMZ3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "W := W-\\alpha\\frac{1}{m} \\sum_{i=1}^{m} (W(x^i)-y^i)x^i\n",
        "$$"
      ],
      "metadata": {
        "id": "3CENCdXbKXIU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# minimize : 경사하강법을 사용\n",
        "# 알파값은 learning rate로 학습률을 지정해준다.\n",
        "# 알파값 이후 부분을 gradient로 표현하고 다음을 정의한다.\n",
        "# 현재 W값에서 학습률 * gradient를 빼주면서 새로운 W(descent)를 구한다.\n",
        "# assign() 함수로 새로운 W값으로 업데이트한다.\n",
        "\n",
        "learning_rate = 0.1\n",
        "gradient = tf.reduce_mean((W * X - Y) * X)\n",
        "descent = W - learning_rate * gradient\n",
        "update = W.assign(descent)\n",
        "\n"
      ],
      "metadata": {
        "id": "XioQH90_Ghh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. 실행\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())"
      ],
      "metadata": {
        "id": "hdAAu37hLd9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. update graph 와 get results\n",
        "\n",
        "# update(X,Y데이터를 주어주면서) -> descent -> gradient\n",
        "# 처음의 W는 랜덤한 값이고, step이 지날수록 1에 가까워진다.\n",
        "\n",
        "for step in range(21):\n",
        "  sess.run(update, feed_dict={X: x_data, Y: y_data})\n",
        "  print(step, sess.run(cost, feed_dict={X:x_data, Y:y_data}), sess.run(W))"
      ],
      "metadata": {
        "id": "tFmB_oMzMzqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "복잡한 cost에서의 Gradient descent"
      ],
      "metadata": {
        "id": "ZaIfCpD2Pptm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 그래프 구현\n",
        "X = [1,2,3]\n",
        "Y = [1,2,3]\n",
        "W = tf.Variable(5.0)\n",
        "\n",
        "  # 가설 설정\n",
        "hypothesis = X * W\n",
        "  # 손실함수 설정\n",
        "cost = tf.reduce_mean(tf.square(hypothesis - Y))"
      ],
      "metadata": {
        "id": "NFbdbQR-NWuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  # minimize\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
        "train = optimizer.minimize(cost)"
      ],
      "metadata": {
        "id": "5DgBZG6sP00G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. 실행\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())"
      ],
      "metadata": {
        "id": "YOIFyx5pP7pk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. update graph 와 get results\n",
        "for step in range(100):\n",
        "  print(step, sess.run(W))\n",
        "  sess.run(train)"
      ],
      "metadata": {
        "id": "7pEBe6A_P_m7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "  option\n",
        "  "
      ],
      "metadata": {
        "id": "mNhis0XPQeI6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 그래프 구현\n",
        "X = [1,2,3]\n",
        "Y = [1,2,3]\n",
        "W = tf.Variable(5.)\n",
        "\n",
        "  # 가설 설정\n",
        "hypothesis = X * W\n",
        "# 추가부분\n",
        "gradient = tf.reduce_mean((W * X - Y)*X)*2\n",
        "  # 손실함수 설정\n",
        "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
        "  # minimize\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)"
      ],
      "metadata": {
        "id": "D4QuSfPBQz35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 추가부분\n",
        "gvs = optimizer.compute_gradients(cost)\n",
        "apply_gradients = optimizer.apply_gradients(gvs)\n",
        "\n",
        "#train = optimizer.minimize(cost)"
      ],
      "metadata": {
        "id": "Q-vMKqtxQz36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. 실행\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())"
      ],
      "metadata": {
        "id": "hKzKG8bzQz36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. update graph 와 get results\n",
        "for step in range(100):\n",
        "  print(step, sess.run([gradient, W, gvs]))\n",
        "  sess.run(apply_gradients)"
      ],
      "metadata": {
        "id": "60BzdtebQz36"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}